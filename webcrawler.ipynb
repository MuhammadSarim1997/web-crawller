{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webcrawler.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIq0VVDjglI6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from selenium import webdriver \n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib\n",
        "from urllib.request import urlopen\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import time\n",
        "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
        "\n",
        "\n",
        "x = 0\n",
        "website_pages = []\n",
        "name = []\n",
        "Url = [\"hello\"]\n",
        "Price = []\n",
        "ArrayN = np.array(name)\n",
        "ArrayU = np.array(Url)\n",
        "ArrayP = np.array(Price)\n",
        "\n",
        "#\"\"\"\"\"\n",
        "for x in range (2,3):\n",
        "    y = \"https://www.daraz.pk/skincare/?page={}&price=1000-&style=wf\".format(x+1)\n",
        "    website_pages.append(y)\n",
        "    #print (website_pages)\n",
        "    #\"\"\"\"\n",
        "\n",
        "    #inks_df = pd.DataFrame(website_page)\n",
        "array1 = np.array(website_pages)\n",
        "df1 = pd.DataFrame(columns = ['Name','Price','Url'])\n",
        "i = 0\n",
        "a = 0\n",
        "b = 0\n",
        "\n",
        "for x in website_pages:\n",
        "    driver = webdriver.Chrome(PATH)\n",
        "    #options = webdriver.ChromeOptions()z\n",
        "    #options.add_argument('headless')\n",
        "    #capa = DesiredCapabilities.CHROME\n",
        "    #capa[\"pageLoadStrategy\"] = \"none\"\n",
        "    #driver = webdriver.Chrome(PATH, options=options, desired_capabilities=capa)\n",
        "    #driver.set_window_size(1440,900)\n",
        "    page = driver.get(x)\n",
        "    #driver.set_window_size(1440,900)\n",
        "    #SCROLL_PAUSE_TIME = 0.5\n",
        "    time.sleep(3)\n",
        "    body = driver.find_element_by_tag_name('html')\n",
        "    for x in range (0,100):\n",
        "     body.send_keys(Keys.PAGE_DOWN)\n",
        "\n",
        "\n",
        "\n",
        "    # Get scroll height\n",
        "    #driver.execute_script(\"window.scrollTo(0, 1000);\")\n",
        "    \n",
        "    #    \"\"\"\"\"\n",
        "    #   try :\n",
        "    #   price = driver.find_element_by_class_name(\"price\")\n",
        "    # except :\n",
        "    #   price = driver.find_element_by_class_name(\"price-new\")\n",
        "    #else :\n",
        "    #  price = \"NaN\" \n",
        "    #\n",
        "    #image = driver.find_elements_by_class_name(\"c1ZEkM\")\n",
        "    #image_url = []\n",
        "    #for x in image :\n",
        "    #   img_url = img[x].get('src')\n",
        "    #  print(img_url)\n",
        "    #\"\"\"    \n",
        "    #try:\n",
        "    #    element = WebDriverWait(driver, 120).until(\n",
        "    #      EC.presence_of_element_located((By.ID, \"product-collection-image-365467\"))\n",
        "    # )\n",
        "    #finally:\n",
        "    #print(\"help\")\n",
        "    product_items = []\n",
        "    #soup = BeautifulSoup(urllib.request.urlopen(x,\"timeout\" = 50).read())\n",
        "    soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
        "    product_items = soup.find_all(\"div\", attrs={\"data-qa-locator\" : \"product-item\"})\n",
        "    product_name = soup.find_all(\"div\", attrs={\"class\" : \"c16H9d\"})\n",
        "    product_price = soup.find_all(\"div\", attrs={\"class\" : \"c3gUW0\"})\n",
        "    #print(product_items[0])\n",
        "    #print(product_price)\n",
        "    #print(product_items)\n",
        "    #print(product_items.prettify())\n",
        "    #print(product_items.div.div.div.div.a.img)\n",
        "    #product_items = soup.find_all(\"div\", attrs={\"data-qa-locator\": \"product-item\"})\n",
        "        #img =soup.find_all(\"img\" , {'class' : 'c1ZEkM'})\n",
        "    page_url = []\n",
        "    image_src = []\n",
        "    item_url = []\n",
        "    \n",
        "    \n",
        "    for item in product_items:\n",
        "        #name = item.a.get(\"title\")\n",
        "        #print(name)\n",
        "        item_url = item.a.get('href')\n",
        "        #print(item_url)\n",
        "        #print(item.contents)\n",
        "        #item_image =item.img.get('src')\n",
        "        #print(item_image)\n",
        "        \n",
        "        \n",
        "        #try :\n",
        "         #print(image_url)\n",
        "        #print(len(item_url))\n",
        "        #print(len(image_url))\n",
        "        #image_url = f\"https:{item.find('img')['src']}\"\n",
        "        #print(image_url)\n",
        "        df1.loc[i,['Url']]= item_url\n",
        "        i = i + 1\n",
        "        \n",
        "    for item in product_name:\n",
        "        name = item.a.text\n",
        "        #print(name)\n",
        "        df1.loc[a,['Name']]= name\n",
        "        a = a + 1\n",
        "        \n",
        "    for item in product_price:\n",
        "        price = item.span.text\n",
        "        #print(price)\n",
        "        df1.loc[b,['Price']]= price\n",
        "        b = b + 1\n",
        "    \n",
        "    \n",
        "    \n",
        "    print(df1)\n",
        "    #name = driver.find_element_by_css_selector(\"div.product-item\")\n",
        "    #print(name.get_attribute(\"src\"))\n",
        "    #price = driver.find_elements_by_class_name(\"price\")\n",
        "    #url = driver.find_children_by_class_name(\"product-name\")\n",
        "    #url =  name.find_elements_by_tag_name(\"a\")\n",
        "    #image = driver.find_elements_by_class_name(\"woo-entry-image-main lazyloaded\")\n",
        "    \n",
        "    #for a in range(0, 40):\n",
        "     #   df1.loc[i,['Name']]= name[a].textz\n",
        "      #  df1.loc[i,['Price']]= price[a].text\n",
        "       # df1.loc[i,['page-Url']]= item\n",
        "     \n",
        "    print(ArrayU)   \n",
        "    #print(df1)\n",
        "#driver.close()\n",
        "df1.to_csv (\"Daraz-N-url-image.csv\")"
      ]
    }
  ]
}